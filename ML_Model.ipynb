{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\self\\AIM ML Task\\App\\aim\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score, confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB , GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier , ExtraTreesClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import catboost as ctb \n",
    "import lightgbm as lbm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialect</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­ÙŠÙˆÙ†Ù‡ ÙˆÙˆØ­Ø´ÙŠÙ‡ .. ÙˆØªØ·Ù„Ø¨ÙˆÙ† Ù…Ù† Ø§Ù„ØºØ±Ø¨ ÙŠØ­ØªØ±Ù…ÙƒÙ… ÙˆÙŠØ¤Ù…Ù† Ø¨Ø¯ÙŠÙ†ÙƒÙ… ÙˆÙ„Ø§ÙŠÙ†Ø¹ØªÙƒÙ… Ø¨Ø§Ù„Ø¥Ø±Ù‡Ø§Ø¨ ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dialect  \\\n",
       "0      IQ   \n",
       "1      IQ   \n",
       "2      IQ   \n",
       "3      IQ   \n",
       "4      IQ   \n",
       "\n",
       "                                                                                                                        txt  \n",
       "0                                                                          @Nw8ieJUwaCAAreT Ù„ÙƒÙ† Ø¨Ø§Ù„Ù†Ù‡Ø§ÙŠØ© .. ÙŠÙ†ØªÙØ¶ .. ÙŠØºÙŠØ± .  \n",
       "1  @7zNqXP0yrODdRjK ÙŠØ¹Ù†ÙŠ Ù‡Ø°Ø§ Ù…Ø­Ø³ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø´Ø± .. Ø­ÙŠÙˆÙ†Ù‡ ÙˆÙˆØ­Ø´ÙŠÙ‡ .. ÙˆØªØ·Ù„Ø¨ÙˆÙ† Ù…Ù† Ø§Ù„ØºØ±Ø¨ ÙŠØ­ØªØ±Ù…ÙƒÙ… ÙˆÙŠØ¤Ù…Ù† Ø¨Ø¯ÙŠÙ†ÙƒÙ… ÙˆÙ„Ø§ÙŠÙ†Ø¹ØªÙƒÙ… Ø¨Ø§Ù„Ø¥Ø±Ù‡Ø§Ø¨ ..  \n",
       "2                                                                                           @KanaanRema Ù…Ø¨ÙŠÙ† Ù…Ù† ÙƒÙ„Ø§Ù…Ù‡ Ø®Ù„ÙŠØ¬ÙŠ  \n",
       "3                                                                                @HAIDER76128900 ÙŠØ³Ù„Ù…Ù„ÙŠ Ù…Ø±ÙˆØ±Ùƒ ÙˆØ±ÙˆØ­Ùƒ Ø§Ù„Ø­Ù„ÙˆÙ‡ğŸ’  \n",
       "4                                                                                        @hmo2406 ÙˆÙŠÙ† Ù‡Ù„ Ø§Ù„ØºÙŠØ¨Ù‡  Ø§Ø® Ù…Ø­Ù…Ø¯ ğŸŒ¸ğŸŒº  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('full_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217576    #Ù†Ø¬Ø§Ø­_Ø­Ø¬_Ù‡Ø°Ø§_Ø§Ù„Ø¹Ø§Ù…Ù¡Ù¤Ù¤\\n#Ù…Ù†ØªØ¯Ù‰_Ø§Ù„ÙˆØ·Ù†_Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ\\nØ¹Ù„Ù… Ø§Ù„Ù„ÙŠ Ù…Ø§Ù„Ù‡Ù… ØºÙŠØ± Ø§Ù„Ø¯Ø³Ø§ÙŠØ³ Ø­ÙŠÙ„Ù‡\\nØ§Ù„Ø¬ÙŠØ¬ Ø¨Ø®ÙŠØ± ÙˆØ¥Ù†Ø§ ÙƒÙ„Ù†Ø§ Ø®Ø¯Ø§Ù…ÙŠ\\n\\nÙ…Ù…Ù„ÙƒØªÙ†Ø§ Ø¯ÙˆÙ„Ø© ÙƒØ¨Ø±Ù‰ Ù…Ø§Ù‡ÙŠØ¨ Ø¯ÙˆÙŠÙ„Ù‡\\nÙˆØ§Ù„Ù„Ù‡ Ø§Ù„Ù„ÙŠ Ø¹Ø²Ù‡Ø§ Ù…Ù†Ø§Ø±Ø© Ø§Ù„Ø§Ø³Ù„Ø§Ù…ÙŠ\\n\\nØ§Ù„Ø­Ø´ÙˆØ¯ Ø§Ù†Ø¯ÙŠØ±Ù‡Ø§ ÙˆØ§Ù„Ø­Ø±Ø¨ Ù†...\n",
       "344491                                                                  Ø¨Ù†ÙØ³ Ù‡Ø§Ù„ÙŠÙˆÙ… Ù‚Ø¨Ù„Ù¢Ù¥Ø³Ù†Ù‡ ØªÙ… Ø§ÙŠÙ‚Ø§Ù Ø³ÙŠØ§Ø±Ù‡ ÙÙŠÙ‡Ø§ Ø£Ø«Ù†ÙŠÙ† Ø´Ø¨Ø§Ø¨ Ø§Ø¹Ù…Ø§Ø±Ù‡Ù… Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² Ù¡Ù¨Ø³Ù†Ù‡ ÙˆØ§Ù„ØªÙ‡Ù…Ù‡ Ø³ÙŠØ§Ø±ØªÙ‡Ù… Ù…Ø´ØºÙ„ÙŠÙ†Ù‡Ø§ Ø¨Ø¯ÙˆÙ† Ù…ÙØªØ§Ø­(Ø¬Ø·Ù„)ÙƒÙ„Ø¨Ú†ÙˆÙ‡Ù… Ø§ÙŠØ¯Ù‡Ù… Ù„Ù„Ø®Ù„Ù1âƒ£\n",
       "380119                                                                                                                                            @Mralseyabi @m_namani Ø§Ø­Ø³Ù† Ø§Ù„Ø¸Ù† ÙÙŠÙ‡Ù… ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ¨Ù† Ø­Ø§Ø¬Ø© Ø­Ù„ÙˆØ© Ø¹Ù†Ø¯Ù‡Ù…\n",
       "Name: txt, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.txt.sample(3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txt = data.txt.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109133    Ø±Ø­ Ù†Ø§ÙƒÙ„ Ø®Ø±Ø§ Ø¨Ø±ÙŠØ­Ù‡ Ø§Ù„Ø¬Ù…Ø§Ø¹Ù‡  Ø¹Ø¯Ù‡ Ø¨Ø·Ù„Ø¹ Ù‚Ø§Ø¦Ø¯ Ø¹Ø±Øµ Ø¨ÙŠØ­Ø´Ø± Ø·ÙŠØ²Ù‡  Ø¬ÙˆÙ„Ø§Ù†\n",
       "10932                                            ÙˆØ§Ù„Ù„Ù‡ Ù…Ø§Ø¨ÙŠÙ‡Ù… Ø§Ù„ÙŠØ­Ø¬ÙŠ ØµØ¯Ú¯\n",
       "224136                   Ø´ÙƒØ±Ø§  Ø­Ø±Ù  Ù‚Ù„ØªÙŠÙ‡  ÙˆÙŠØ§Ø±ÙŠØª Ø§Ù„Ù†Ø§Ø³  ØªØªØ¹Ù„Ù… Ù…Ù†Ùƒ ÙˆØªÙÙ‡Ù…\n",
       "Name: txt, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.txt.sample(3,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting to train_valid_test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         4\n",
       "1         4\n",
       "2         4\n",
       "3         4\n",
       "4         4\n",
       "         ..\n",
       "458192    1\n",
       "458193    1\n",
       "458194    1\n",
       "458195    1\n",
       "458196    1\n",
       "Name: dialect, Length: 458197, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "data['dialect'] = le.fit_transform(data['dialect'])\n",
    "data['dialect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458197, 0.054561684166417504)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), 25000/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     57636\n",
       "11    43742\n",
       "6     42109\n",
       "8     36499\n",
       "12    31069\n",
       "5     27921\n",
       "7     27617\n",
       "13    26832\n",
       "0     26296\n",
       "1     26292\n",
       "10    19116\n",
       "15    16242\n",
       "2     16183\n",
       "4     15497\n",
       "14    14434\n",
       "9     11539\n",
       "17     9927\n",
       "16     9246\n",
       "Name: dialect, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dialect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test sets\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(data['txt'],data['dialect'],test_size=0.05,random_state=45,shuffle=True, stratify = data['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435287, 0.05743337154566987)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain),25000/len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xvalid,ytrain,yvalid=train_test_split(xtrain,ytrain,test_size=0.05,random_state=45,shuffle=True,stratify = ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorzers\n",
    "cvec = CountVectorizer()\n",
    "hvec = HashingVectorizer(ngram_range=(2,5), n_features=50000)\n",
    "tvec = TfidfVectorizer(max_features=80000,ngram_range=(3,8),analyzer='char')\n",
    "\n",
    "## classifiers\n",
    "rf = RandomForestClassifier()\n",
    "adac = AdaBoostClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "catc = ctb.CatBoostClassifier()\n",
    "lbmc = lbm.LGBMClassifier()\n",
    "\n",
    "lrc =LogisticRegression()\n",
    "svc = SVC()\n",
    "mnbc = MultinomialNB()\n",
    "bnbc = BernoulliNB()\n",
    "gnbc = GaussianNB()\n",
    "\n",
    "## label encoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('tfidf', hvec),\n",
    "    ('clf', gnbc ),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(xtrain,ytrain)\n",
    "preds = pipe.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12514185945002182"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030753352297550163"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest, preds, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets/mlmodel.pkl', 'wb') as model:\n",
    "    pickle.dump(pipe,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets/le.pkl', 'wb') as lencoder:\n",
    "    pickle.dump(le,lencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets/mlmodel.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45384792097404086, 0.3926517839188842)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(xvalid)\n",
    "accuracy_score(yvalid,preds), f1_score(yvalid,preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005bf040230a0d411425b97bf046d89bfd90c8a9c6ecb15bf71aa6f47ab3b4a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
