{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\self\\AIM ML Task\\App\\aim\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,f1_score, confusion_matrix, plot_confusion_matrix, classification_report\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB , GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier , ExtraTreesClassifier, RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import catboost as ctb \n",
    "import lightgbm as lbm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialect</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. حيونه ووحشيه .. وتطلبون من الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب ..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@KanaanRema مبين من كلامه خليجي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@HAIDER76128900 يسلملي مرورك وروحك الحلوه💐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IQ</td>\n",
       "      <td>@hmo2406 وين هل الغيبه  اخ محمد 🌸🌺</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dialect  \\\n",
       "0      IQ   \n",
       "1      IQ   \n",
       "2      IQ   \n",
       "3      IQ   \n",
       "4      IQ   \n",
       "\n",
       "                                                                                                                        txt  \n",
       "0                                                                          @Nw8ieJUwaCAAreT لكن بالنهاية .. ينتفض .. يغير .  \n",
       "1  @7zNqXP0yrODdRjK يعني هذا محسوب على البشر .. حيونه ووحشيه .. وتطلبون من الغرب يحترمكم ويؤمن بدينكم ولاينعتكم بالإرهاب ..  \n",
       "2                                                                                           @KanaanRema مبين من كلامه خليجي  \n",
       "3                                                                                @HAIDER76128900 يسلملي مرورك وروحك الحلوه💐  \n",
       "4                                                                                        @hmo2406 وين هل الغيبه  اخ محمد 🌸🌺  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('full_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217576    #نجاح_حج_هذا_العام١٤٤\\n#منتدى_الوطن_السعودي\\nعلم اللي مالهم غير الدسايس حيله\\nالجيج بخير وإنا كلنا خدامي\\n\\nمملكتنا دولة كبرى ماهيب دويله\\nوالله اللي عزها منارة الاسلامي\\n\\nالحشود انديرها والحرب ن...\n",
       "344491                                                                  بنفس هاليوم قبل٢٥سنه تم ايقاف سياره فيها أثنين شباب اعمارهم لا تتجاوز ١٨سنه والتهمه سيارتهم مشغلينها بدون مفتاح(جطل)كلبچوهم ايدهم للخلف1⃣\n",
       "380119                                                                                                                                            @Mralseyabi @m_namani احسن الظن فيهم يمكن التبن حاجة حلوة عندهم\n",
       "Name: txt, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.txt.sample(3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.txt = data.txt.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109133    رح ناكل خرا بريحه الجماعه  عده بطلع قائد عرص بيحشر طيزه  جولان\n",
       "10932                                            والله مابيهم اليحجي صدگ\n",
       "224136                   شكرا  حرف  قلتيه  وياريت الناس  تتعلم منك وتفهم\n",
       "Name: txt, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.txt.sample(3,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting to train_valid_test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         4\n",
       "1         4\n",
       "2         4\n",
       "3         4\n",
       "4         4\n",
       "         ..\n",
       "458192    1\n",
       "458193    1\n",
       "458194    1\n",
       "458195    1\n",
       "458196    1\n",
       "Name: dialect, Length: 458197, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "data['dialect'] = le.fit_transform(data['dialect'])\n",
    "data['dialect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458197, 0.054561684166417504)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), 25000/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     57636\n",
       "11    43742\n",
       "6     42109\n",
       "8     36499\n",
       "12    31069\n",
       "5     27921\n",
       "7     27617\n",
       "13    26832\n",
       "0     26296\n",
       "1     26292\n",
       "10    19116\n",
       "15    16242\n",
       "2     16183\n",
       "4     15497\n",
       "14    14434\n",
       "9     11539\n",
       "17     9927\n",
       "16     9246\n",
       "Name: dialect, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dialect'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test sets\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(data['txt'],data['dialect'],test_size=0.05,random_state=45,shuffle=True, stratify = data['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435287, 0.05743337154566987)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain),25000/len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xvalid,ytrain,yvalid=train_test_split(xtrain,ytrain,test_size=0.05,random_state=45,shuffle=True,stratify = ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vectorzers\n",
    "cvec = CountVectorizer()\n",
    "hvec = HashingVectorizer(ngram_range=(2,5), n_features=50000)\n",
    "tvec = TfidfVectorizer(max_features=80000,ngram_range=(3,8),analyzer='char')\n",
    "\n",
    "## classifiers\n",
    "rf = RandomForestClassifier()\n",
    "adac = AdaBoostClassifier()\n",
    "xgbc = xgb.XGBClassifier()\n",
    "catc = ctb.CatBoostClassifier()\n",
    "lbmc = lbm.LGBMClassifier()\n",
    "\n",
    "lrc =LogisticRegression()\n",
    "svc = SVC()\n",
    "mnbc = MultinomialNB()\n",
    "bnbc = BernoulliNB()\n",
    "gnbc = GaussianNB()\n",
    "\n",
    "## label encoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[\n",
    "    ('tfidf', hvec),\n",
    "    ('clf', gnbc ),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(xtrain,ytrain)\n",
    "preds = pipe.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12514185945002182"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030753352297550163"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ytest, preds, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets/mlmodel.pkl', 'wb') as model:\n",
    "    pickle.dump(pipe,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets/le.pkl', 'wb') as lencoder:\n",
    "    pickle.dump(le,lencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('assets/mlmodel.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45384792097404086, 0.3926517839188842)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(xvalid)\n",
    "accuracy_score(yvalid,preds), f1_score(yvalid,preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005bf040230a0d411425b97bf046d89bfd90c8a9c6ecb15bf71aa6f47ab3b4a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
